{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook corresponds to mission 17 of [dataquest](https://www.dataquest.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding while importing data**\n",
    "<br>\n",
    "<br>_Most used:_\n",
    "* Default: encoding = \"UTF-8\"\n",
    "* \"Latin-1\" (also known as ISO-8895-1)\n",
    "* \"Windows-1251\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1303 entries, 0 to 1302\n",
      "Data columns (total 13 columns):\n",
      "Manufacturer                1303 non-null object\n",
      "Model Name                  1303 non-null object\n",
      "Category                    1303 non-null object\n",
      "Screen Size                 1303 non-null object\n",
      "Screen                      1303 non-null object\n",
      "CPU                         1303 non-null object\n",
      "RAM                         1303 non-null object\n",
      " Storage                    1303 non-null object\n",
      "GPU                         1303 non-null object\n",
      "Operating System            1303 non-null object\n",
      "Operating System Version    1133 non-null object\n",
      "Weight                      1303 non-null object\n",
      "Price (Euros)               1303 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 132.4+ KB\n"
     ]
    }
   ],
   "source": [
    "laptops= pd.read_csv(\"laptops.csv\", encoding=\"Latin-1\")\n",
    "laptops.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case UTF-8 will return a error\n",
    "#laptops1 = pd.read_csv(\"laptops.csv\", encoding=\"UTF-8\") #Or pd.read_csv(\"laptops.csv\")\n",
    "#laptops1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1303 entries, 0 to 1302\n",
      "Data columns (total 13 columns):\n",
      "Manufacturer                1303 non-null object\n",
      "Model Name                  1303 non-null object\n",
      "Category                    1303 non-null object\n",
      "Screen Size                 1303 non-null object\n",
      "Screen                      1303 non-null object\n",
      "CPU                         1303 non-null object\n",
      "RAM                         1303 non-null object\n",
      " Storage                    1303 non-null object\n",
      "GPU                         1303 non-null object\n",
      "Operating System            1303 non-null object\n",
      "Operating System Version    1133 non-null object\n",
      "Weight                      1303 non-null object\n",
      "Price (Euros)               1303 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 132.4+ KB\n"
     ]
    }
   ],
   "source": [
    "laptops2 = pd.read_csv(\"laptops.csv\", encoding=\"Windows-1251\")\n",
    "laptops2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that our file has loaded well in all encodes above, but there will be times that the file won't open correctly without its correct encode**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'Model Name', 'Category', 'Screen Size', 'Screen',\n",
       "       'CPU', 'RAM', ' Storage', 'GPU', 'Operating System',\n",
       "       'Operating System Version', 'Weight', 'Price (Euros)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing any whitespace from the start and end of the labels - if you look closely you'll notice that the \" Storage\" column label has a space in front of it. These quirks with column labels are often hard to spot, so removing them at the start will save you pain in the long run.\n",
    "* Replacing spaces with underscores and remove special characters - this will make things consistent, and also allows for the use of dot accessors for those who prefer that.\n",
    "* Make all labels lowercase - this is good for consistency, and means you'll never have to remember what is capitalized and how.\n",
    "Shorten any long column names - this helps to keep your code easier to read, especially when you are using method chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['manufacturer', 'model_name', 'category', 'screen_size', 'screen',\n",
       "       'cpu', 'ram', 'storage', 'gpu', 'os', 'os_version', 'weight',\n",
       "       'price_euros'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a method to clean the names\n",
    "def name_cleaning(col):\n",
    "    col = col.replace(\"Operating System\", \"os\")\n",
    "    col = col.strip() #Cleans space at begining and the end of the string\n",
    "    col = col.replace(\" \", \"_\")\n",
    "    col = col.replace(\"(\", \"\")\n",
    "    col = col.replace(\")\", \"\")\n",
    "    col = col.lower()\n",
    "    return col\n",
    "\n",
    "#Creating a list to receive the cleaned names\n",
    "new_col_names = []\n",
    "\n",
    "#looping through the column names\n",
    "for col_name in laptops.columns:\n",
    "    new_col_names.append(name_cleaning(col_name))\n",
    "    \n",
    "#Passing the values\n",
    "laptops.columns = new_col_names\n",
    "laptops.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text to numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we're converting text to numeric data, we can follow this data cleaning workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cleaning_workflow.svg\" style=\"height:250px;float:left;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Screen_size**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explore data in column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['13.3\"', '15.6\"', '15.4\"', '14.0\"', '12.0\"', '11.6\"', '17.3\"',\n",
       "       '10.1\"', '13.5\"', '12.5\"', '13.0\"', '18.4\"', '13.9\"', '12.3\"',\n",
       "       '17.0\"', '15.0\"', '14.1\"', '11.3\"'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"screen_size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Identify patterns and special cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the code above [unique](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) is realy useful when it comes to first explore a column, we can see that there is no null values in the column and all values are numeric with quotation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove non-digit characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13.3' '15.6' '15.4' '14.0' '12.0' '11.6' '17.3' '10.1' '13.5' '12.5'\n",
      " '13.0' '18.4' '13.9' '12.3' '17.0' '15.0' '14.1' '11.3']\n"
     ]
    }
   ],
   "source": [
    "#For our analyses the quotation marks wont be necessary, and working with numeric values for screen size will help us.\n",
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].str.replace('\"','')\n",
    "\n",
    "print(laptops[\"screen_size\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** In the code above in order to avoid unnecessary loops,  has been used [series.str.replace](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html) instead of just .replace(), this is really important because we are working with a vector (pd.series), and the serires.str.replace is a vectorized str.replace(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Convert the column to a numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "#Float will be used, since some values have decimals\n",
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].astype(float)\n",
    "\n",
    "print(laptops[\"screen_size\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Rename column (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manufacturer           object\n",
      "model_name             object\n",
      "category               object\n",
      "screen_size_inches    float64\n",
      "screen                 object\n",
      "cpu                    object\n",
      "ram                    object\n",
      "storage                object\n",
      "gpu                    object\n",
      "os                     object\n",
      "os_version             object\n",
      "weight                 object\n",
      "price_euros            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "laptops.rename({\"screen_size\": \"screen_size_inches\"}, axis=1, inplace=True)\n",
    "print(laptops.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples:\n",
    "The same as above, but for the column 'ram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['8GB', '16GB', '4GB', '2GB', '12GB', '6GB', '32GB', '24GB', '64GB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops['ram'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manufacturer           object\n",
       "model_name             object\n",
       "category               object\n",
       "screen_size_inches    float64\n",
       "screen                 object\n",
       "cpu                    object\n",
       "ram_gb                  int32\n",
       "storage                object\n",
       "gpu                    object\n",
       "os                     object\n",
       "os_version             object\n",
       "weight                 object\n",
       "price_euros            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops['ram'] = laptops['ram'].str.replace('GB', '').astype(int)\n",
    "laptops.rename({'ram':'ram_gb'}, inplace=True, axis=1)\n",
    "laptops.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is other problems that may appear like in the weight column, that the text with the numeric may vary ('kg' or 'kgs').\n",
    "<br> Other problems are dot/comma with numerical values, python will use dot, so whenever numeric values use comma, like in the price column it must be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights:  ['1.37kg', '1.34kg', '1.86kg', '1.83kg']\n",
      "Some prices:  ['1339,69', '898,94', '575,00', '2537,45']\n"
     ]
    }
   ],
   "source": [
    "print(\"Some weights: \", list(laptops.loc[:3,\"weight\"]))\n",
    "print(\"Some prices: \", list(laptops.loc[:3,\"price_euros\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights:  [1.37, 1.34, 1.86, 1.83]\n",
      "Some prices:  [1339.69, 898.94, 575.0, 2537.45]\n"
     ]
    }
   ],
   "source": [
    "laptops[\"weight\"] = (laptops[\"weight\"]\n",
    "                        .str.replace(\"kgs\", \"\")\n",
    "                        .str.replace(\"kg\", \"\")\n",
    "                        .astype(float)\n",
    "                    )\n",
    "laptops[\"price_euros\"] = (laptops[\"price_euros\"]\n",
    "                        .str.replace(\",\", \".\")\n",
    "                        .astype(float)\n",
    "                    )\n",
    "laptops.rename({\"weight\":\"weight_kg\"}, axis=1, inplace=True)\n",
    "\n",
    "print(\"Some weights: \", list(laptops.loc[:3,\"weight_kg\"]))\n",
    "print(\"Some prices: \", list(laptops.loc[:3,\"price_euros\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always important to rembember [series.describe()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.describe.html) that give us the basic statistics of a serie:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1303.000000\n",
       "mean        2.038734\n",
       "std         0.665475\n",
       "min         0.690000\n",
       "25%         1.500000\n",
       "50%         2.040000\n",
       "75%         2.300000\n",
       "max         4.700000\n",
       "Name: weight_kg, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"weight_kg\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Getting a part of the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets take a look at the columns gpu and cpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:\n",
      "0          Intel Core i5 2.3GHz\n",
      "1          Intel Core i5 1.8GHz\n",
      "2    Intel Core i5 7200U 2.5GHz\n",
      "Name: cpu, dtype: object\n",
      "\n",
      "CPU:\n",
      "0    Intel Iris Plus Graphics 640\n",
      "1          Intel HD Graphics 6000\n",
      "2           Intel HD Graphics 620\n",
      "Name: gpu, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU:\")\n",
    "print(laptops[\"cpu\"].head(3))\n",
    "print(\"\\nCPU:\")\n",
    "print(laptops[\"gpu\"].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, in both columns the data starts with the manufacturer as the first word. <br>\n",
    "So we will try to create columns of just the manufacturer, for this we will use [Series.str.split()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html), wich is a vectorize split. Split creates a list by separating words as elements by spaces on the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops[\"gpu_manufacturer\"] = (laptops[\"gpu\"]\n",
    "                                    .str.split(n=1,expand=True) \n",
    "                                    .iloc[:,0]\n",
    "                               )\n",
    "laptops[\"cpu_manufacturer\"] = (laptops[\"cpu\"]\n",
    "                                    .str.split(n=1, expand=True)\n",
    "                                    .iloc[:,0]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:**\n",
    "* **n** is a parameter that you can limit how many splits you want. By passing 1, you divide the string in a list of two elements, the first word and the rest of the string.\n",
    "* **expand** when is set as TRUE, the series split creates a DataFrame into a DataFrame, in other words, expand the splitted strings into separate columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"str_split_4.svg\" style=\"height:150px;float:left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Getting text on other positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look ate the screen column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IPS Panel Retina Display 2560x1600', '1440x900',\n",
       "       'Full HD 1920x1080', 'IPS Panel Retina Display 2880x1800',\n",
       "       '1366x768', 'IPS Panel Full HD 1920x1080',\n",
       "       'IPS Panel Retina Display 2304x1440',\n",
       "       'IPS Panel Full HD / Touchscreen 1920x1080',\n",
       "       'Full HD / Touchscreen 1920x1080',\n",
       "       'Touchscreen / Quad HD+ 3200x1800'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"screen\"].unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the resolution is in the last position, but if we use split would problem, because it will start by the left and then will mess up the reolustions positions as we can see bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1          2        3          4\n",
      "0       IPS  Panel     Retina  Display  2560x1600\n",
      "1  1440x900   None       None     None       None\n",
      "2      Full     HD  1920x1080     None       None\n",
      "3       IPS  Panel     Retina  Display  2880x1800\n",
      "4       IPS  Panel     Retina  Display  2560x1600\n"
     ]
    }
   ],
   "source": [
    "print(laptops.loc[:4, \"screen\"].str.split(expand=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For solving this problem will be used [series.str.rsplit()](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.rsplit.html), which splits from the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          0          1\n",
      "0  IPS Panel Retina Display  2560x1600\n",
      "1                  1440x900       None\n",
      "2                   Full HD  1920x1080\n",
      "3  IPS Panel Retina Display  2880x1800\n",
      "4  IPS Panel Retina Display  2560x1600\n"
     ]
    }
   ],
   "source": [
    "print(laptops.loc[:4, \"screen\"].str.rsplit(n=1, expand=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last result is much closer from what we are looking for.<br>\n",
    "The problem now resumes to some lines where the right column is None, but always in those places the value on the left column is the resolution, so it just some treatment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          A          B\n",
      "0  IPS Panel Retina Display  2560x1600\n",
      "1                  1440x900   1440x900\n",
      "2                   Full HD  1920x1080\n",
      "3  IPS Panel Retina Display  2880x1800\n",
      "4  IPS Panel Retina Display  2560x1600\n",
      "5                  1366x768   1366x768\n",
      "6  IPS Panel Retina Display  2880x1800\n",
      "7                  1440x900   1440x900\n",
      "8                   Full HD  1920x1080\n",
      "9         IPS Panel Full HD  1920x1080\n"
     ]
    }
   ],
   "source": [
    "df_res = laptops[\"screen\"].str.rsplit(n=1, expand=True)\n",
    "df_res.columns = [\"A\", \"B\"] # giving the columns string labels makes them easier to work with\n",
    "df_res.loc[df_res[\"B\"].isnull(), \"B\"] = df_res[\"A\"]  #Where the column B is null, pass the A value to it\n",
    "print(df_res.iloc[:10]) #Confirming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2560x1600' '1440x900' '1920x1080' '2880x1800' '1366x768' '2304x1440'\n",
      " '3200x1800' '1920x1200' '2256x1504' '3840x2160' '2160x1440' '2560x1440'\n",
      " '1600x900' '2736x1824' '2400x1600']\n"
     ]
    }
   ],
   "source": [
    "laptops[\"screen_resolution\"] = df_res[\"B\"]\n",
    "print(laptops[\"screen_resolution\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example:\n",
    "Now lets extract the speed from cpu column, but this time we can extract as float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Intel Core i5 2.3GHz', 'Intel Core i5 1.8GHz',\n",
       "       'Intel Core i5 7200U 2.5GHz', 'Intel Core i7 2.7GHz',\n",
       "       'Intel Core i5 3.1GHz'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"cpu\"].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.3\n",
       "1    1.8\n",
       "2    2.5\n",
       "3    2.7\n",
       "Name: B, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a DataFrame separating the last word in a diffrent column from the rest of the string\n",
    "df_cpu_speed = laptops[\"cpu\"].str.rsplit(n=1, expand=True)\n",
    "df_cpu_speed.columns = [\"A\", \"B\"]  # giving the columns string labels makes them easier to work with\n",
    "df_cpu_speed[\"B\"] = (df_cpu_speed[\"B\"]\n",
    "                                     .str.replace(\"GHz\", \"\")\n",
    "                                     .astype(float)\n",
    "                    )\n",
    "df_cpu_speed.loc[:3, \"B\"] #Confirming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3 , 1.8 , 2.5 , 2.7 , 3.1 , 3.  , 2.2 , 1.6 , 2.  , 2.8 , 1.2 ,\n",
       "       2.9 , 2.4 , 1.44, 1.5 , 1.9 , 1.1 , 1.3 , 2.6 , 3.6 , 3.2 , 1.  ,\n",
       "       2.1 , 0.9 , 1.92])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"cpu_speed_ghz\"] = df_cpu_speed[\"B\"] \n",
    "laptops[\"cpu_speed_ghz\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Inconsistent Values\n",
    "**(really frequent issue)**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way it could be fixed is by using a boolean comparison and assignment (as we did before), but normally we may find multipple inconsisteces. Because of this the method which is most used is: the [Series.map()](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) method. <br>\n",
    "For this first we will work upon a simple example, a series with multiple errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     oranje\n",
       "1    bananna\n",
       "2       pair\n",
       "3     oranje\n",
       "4     oranje\n",
       "5     oranje\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_array = np.array([\"oranje\", \"bananna\", \"pair\", \"oranje\", \"oranje\", \"oranje\"])\n",
    "fruit_series = pd.Series(fruit_array)\n",
    "fruit_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    orange\n",
       "1    banana\n",
       "2      pear\n",
       "3    orange\n",
       "4    orange\n",
       "5    orange\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First the map method requires a dictionary with the corrections\n",
    "fruits_correction = {\n",
    "                \"oranje\" : \"orange\",\n",
    "                \"pair\" : \"pear\",\n",
    "                \"bananna\" : \"banana\"\n",
    "}\n",
    "\n",
    "#Apply the method\n",
    "fruit_series = fruit_series.map(fruits_correction)\n",
    "fruit_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is a problem in pd.Series.map() method, wich is: if there ins't a value that is equal to one of the dictionary's keys, this value will be turned into None or NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1    Key_found\n",
       "2          NaN\n",
       "3          NaN\n",
       "4          NaN\n",
       "5          NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_test = {\n",
    "                \"banana\" : \"Key_found\"\n",
    "}\n",
    "fruit_series = fruit_series.map(key_test)\n",
    "fruit_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Applying to our Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Windows      1125\n",
       "No OS          66\n",
       "Linux          62\n",
       "Chrome OS      27\n",
       "macOS          13\n",
       "Mac OS          8\n",
       "Android         2\n",
       "Name: os, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"os\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, there is a repetion on the Apple's operating system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Windows      1125\n",
       "No OS          66\n",
       "Linux          62\n",
       "Chrome OS      27\n",
       "macOS          21\n",
       "Android         2\n",
       "Name: os, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mac_correction = {\n",
    "                'Android': 'Android',\n",
    "                'Chrome OS': 'Chrome OS',\n",
    "                'Linux': 'Linux',\n",
    "                'Mac OS': 'macOS',\n",
    "                'No OS': 'No OS',\n",
    "                'Windows': 'Windows',\n",
    "                'macOS': 'macOS'\n",
    "                }\n",
    "\n",
    "laptops[\"os\"] = laptops[\"os\"].map(mac_correction)\n",
    "laptops[\"os\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Treating Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying:** There are two approaches we can use: the DataFrame.info() method and the DataFrame.isnull() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1303 entries, 0 to 1302\n",
      "Data columns (total 17 columns):\n",
      "manufacturer          1303 non-null object\n",
      "model_name            1303 non-null object\n",
      "category              1303 non-null object\n",
      "screen_size_inches    1303 non-null float64\n",
      "screen                1303 non-null object\n",
      "cpu                   1303 non-null object\n",
      "ram_gb                1303 non-null int32\n",
      "storage               1303 non-null object\n",
      "gpu                   1303 non-null object\n",
      "os                    1303 non-null object\n",
      "os_version            1133 non-null object\n",
      "weight_kg             1303 non-null float64\n",
      "price_euros           1303 non-null float64\n",
      "gpu_manufacturer      1303 non-null object\n",
      "cpu_manufacturer      1303 non-null object\n",
      "screen_resolution     1303 non-null object\n",
      "cpu_speed_ghz         1303 non-null float64\n",
      "dtypes: float64(4), int32(1), object(12)\n",
      "memory usage: 168.0+ KB\n"
     ]
    }
   ],
   "source": [
    "laptops.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two downsides to this approach - firstly the information is printed, so we can't easily work with it, and secondly looking at the number of non-null values can be harder to understand than looking at the number of null values. In contrast, DataFrame.isnull() returns a boolean dataframe with True and False indications for every value in the dataframe, and then we can use DataFrame.sum() to give us accountsâ€“ using a .sum() method on a boolean array will give us a count of the True values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manufacturer            0\n",
       "model_name              0\n",
       "category                0\n",
       "screen_size_inches      0\n",
       "screen                  0\n",
       "cpu                     0\n",
       "ram_gb                  0\n",
       "storage                 0\n",
       "gpu                     0\n",
       "os                      0\n",
       "os_version            170\n",
       "weight_kg               0\n",
       "price_euros             0\n",
       "gpu_manufacturer        0\n",
       "cpu_manufacturer        0\n",
       "screen_resolution       0\n",
       "cpu_speed_ghz           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treating options:**\n",
    "* Remove any rows that have missing values.\n",
    "* Remove any columns that have missing values.\n",
    "* Fill the missing values with some other value.\n",
    "* Leave the missing values as is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two options, removing columns and/or rows with missing values is often used when preparing data for machine learning, as machine learning algorithms are unable to be trained on data that includes null values. The methods that we use to remove rows and columns with null values is the [DataFrame.dropna()](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method. As a result, removing columns and rows is commonly known as dropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** Dropna deletes row or column wich has a null value on it.<br>\n",
    "Choosing if it is a column or row, depends on the axis parameter pass to it: \n",
    "axis=1(Columns) axis=0(Rows).\n",
    "<br>Remembering that axis default value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops_no_null_rows = laptops.dropna()\n",
    "laptops_no_null_cols = laptops.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Treating without removing entire lines or columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for treating the null values, but without removing whole lines or columns, because would may intefer directly on our analysis.\n",
    " One method is to explore all of the values in the column, for this we can use Series.value_counts() with the dropna=False parameter.  default, Series.value_counts() won't include null values in its output. This parameter allows us to explicitly indicate we want to see the null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10      1072\n",
      "NaN      170\n",
      "7         45\n",
      "X          8\n",
      "10 S       8\n",
      "Name: os_version, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(laptops[\"os_version\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let see how are the OS's of the null values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No OS        66\n",
      "Linux        62\n",
      "Chrome OS    27\n",
      "macOS        13\n",
      "Android       2\n",
      "Name: os, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "os_with_null_values = laptops.loc[\n",
    "                                laptops[\"os_version\"].isnull(),\n",
    "                                \"os\"\n",
    "                                ]\n",
    "print(os_with_null_values.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we can observe a few things:\n",
    "* Most of the missing values are actually when the laptop doesn't include any OS. This is an important distinction, because it's not so much that we don't know what the value is, as that there can't be a value.\n",
    "* 13 of the laptops that come with macOS do not specify the version. Leaning on our knowledge of MacOS, we might know that the full name of macOS used to be Mac OS X, and so we might to fill these values to be more consistent.\n",
    "\n",
    "In both of these cases, we can fill the missing values to make our data more correct. For the rest of the values, it's probably best to leave them as missing so we don't remove important values.<br>\n",
    "First, let's explore those mac columns a bit more to make sure our intuition was correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    13\n",
      "X       8\n",
      "Name: os_version, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mac_os_versions = laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"]\n",
    "\n",
    "print(mac_os_versions.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were correct, all 8 rows that have the value X are macOS versions. We'll fill in all of the NaN values with X. We can use assignment with a boolean comparison to perform this replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"] = \"X\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our other case, let's insert a No OS value into the os_version column for any laptop with a No OS value in the os column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_list_no_os = laptops[\"os\"] == \"No OS\"\n",
    "laptops.loc[bool_list_no_os, \"os_version\"] = \"Version Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_after = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get the storage column and separate it in capacity with gb and type, and do it for 2 memories (max a laptop has on this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70               128GB SSD\n",
      "71               256GB SSD\n",
      "72               256GB SSD\n",
      "73    128GB SSD +  1TB HDD\n",
      "74                 1TB HDD\n",
      "75                 1TB HDD\n",
      "76                 2TB HDD\n",
      "77    128GB SSD +  1TB HDD\n",
      "78                 1TB HDD\n",
      "79    128GB SSD +  1TB HDD\n",
      "80               256GB SSD\n",
      "81               512GB SSD\n",
      "82               256GB SSD\n",
      "83               128GB SSD\n",
      "84                 1TB HDD\n",
      "85    128GB SSD +  1TB HDD\n",
      "86               256GB SSD\n",
      "87               256GB SSD\n",
      "88    128GB SSD +  1TB HDD\n",
      "89               256GB SSD\n",
      "90                 1TB HDD\n",
      "Name: storage, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(laptops.loc[70:90, 'storage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['128GB SSD' '128GB Flash Storage' '256GB SSD' '512GB SSD' '500GB HDD'\n",
      " '256GB Flash Storage' '1TB HDD' '32GB Flash Storage'\n",
      " '128GB SSD +  1TB HDD' '256GB SSD +  256GB SSD' '64GB Flash Storage'\n",
      " '256GB SSD +  1TB HDD' '256GB SSD +  2TB HDD' '32GB SSD' '2TB HDD'\n",
      " '64GB SSD' '1TB Hybrid' '512GB SSD +  1TB HDD' '1TB SSD'\n",
      " '256GB SSD +  500GB HDD' '128GB SSD +  2TB HDD' '512GB SSD +  512GB SSD'\n",
      " '16GB SSD' '16GB Flash Storage' '512GB SSD +  256GB SSD'\n",
      " '512GB SSD +  2TB HDD' '64GB Flash Storage +  1TB HDD' '1GB SSD'\n",
      " '1TB HDD +  1TB HDD' '32GB HDD' '1TB SSD +  1TB HDD'\n",
      " '512GB Flash Storage' '128GB HDD' '240GB SSD' '8GB SSD' '508GB Hybrid'\n",
      " '512GB SSD +  1TB Hybrid' '256GB SSD +  1TB Hybrid']\n"
     ]
    }
   ],
   "source": [
    "print(laptops[\"storage\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def treating_storage(sto_str):\n",
    "    size1 = 0\n",
    "    type1 = None\n",
    "    size2 = None\n",
    "    type2 = None\n",
    "    \n",
    "    sto_list = sto_str.split()\n",
    "    \n",
    "    #Analyzing if there is a second storage \n",
    "    hd2 = False\n",
    "    if(\"+\" in sto_list):\n",
    "            hd2 = True\n",
    "        \n",
    "    #Separating size 1\n",
    "    if(\"TB\" in sto_list[0]):\n",
    "        sto_list[0] = sto_list[0].replace(\"TB\",\"\")\n",
    "        size1 = int(sto_list[0]) * 1000\n",
    "    else:\n",
    "        sto_list[0] = sto_list[0].replace(\"GB\",\"\")\n",
    "        size1 = int(sto_list[0])\n",
    "        \n",
    "    #Separating type 1\n",
    "    if(sto_list[1] == \"Flash\"):\n",
    "        type1 = \"Flash Storage\"\n",
    "        \n",
    "    else:\n",
    "        type1 = sto_list[1]\n",
    "        \n",
    "    #Analysing second storage\n",
    "    if(hd2 == False):\n",
    "        return [size1, type1, size2, type2]\n",
    "    else:\n",
    "        #Locating + position on string list\n",
    "        middle_string_position = sto_list.index(\"+\")\n",
    "        \n",
    "        #Handling size2\n",
    "        if(\"TB\" in sto_list[middle_string_position + 1]):\n",
    "            sto_list[middle_string_position + 1] = sto_list[middle_string_position + 1].replace(\"TB\",\"\")\n",
    "            size2 = int(sto_list[middle_string_position + 1]) * 1000\n",
    "        else:\n",
    "            sto_list[middle_string_position + 1] = sto_list[middle_string_position + 1].replace(\"GB\",\"\")\n",
    "            size2 = int(sto_list[middle_string_position + 1])\n",
    "        \n",
    "        #Handling type2\n",
    "        type2 = sto_list[middle_string_position + 2]\n",
    "        \n",
    "        \n",
    "        return [size1, type1, size2, type2]       \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
